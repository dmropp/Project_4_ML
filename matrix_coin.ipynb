{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import our dependencies\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import sqlite3\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, func, inspect\n",
    "\n",
    "from flask import Flask, jsonify, render_template, request\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqlite3 df interact\n",
    "con = sqlite3.connect(\"movie_ratings_db.sqlite\")\n",
    "links_df = pd.read_sql_query(\"SELECT * FROM Links\", con)\n",
    "movies_df = pd.read_sql_query(\"SELECT * FROM Movies\", con)\n",
    "ratings_df = pd.read_sql_query(\"SELECT * FROM Ratings\", con)\n",
    "tags_df = pd.read_sql_query(\"SELECT * FROM Tags\", con)\n",
    "\n",
    "# map movie titles to Ids using to_dict\n",
    "movie_titles = movies_df.set_index('movieId')['title'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {610}\n",
      " {9724}\n"
     ]
    }
   ],
   "source": [
    "# confirm length of ratings_df, need det for users and movies\n",
    "n_users = len(ratings_df.userId.unique())\n",
    "n_items = len(ratings_df.movieId.unique())\n",
    "print(f'', {n_users})\n",
    "print(f'', {n_items})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight matrix, matrix1 will use n_users, matrix2 will use n_items, \n",
    "# overlap will be n_users to movies that they have rated\n",
    "# class inherits torch.nn, further integration into native pytorch\n",
    "class MatrixFactorization(torch.nn.Module):\n",
    "    # factors default to 20, pair process of users and movies\n",
    "    def __init__(self, n_users, n_items, n_factors=20):\n",
    "        super().__init__()\n",
    "        # unique_user embedding, initialized as lookup tables\n",
    "        self.user_factors = torch.nn.Embedding(n_users, n_factors)\n",
    "        # unique_movie embedding, \"\"\n",
    "        self.item_factors = torch.nn.Embedding(n_items, n_factors)\n",
    "        \n",
    "        # lookup tables, embeddings, initialized small random values \n",
    "        self.user_factors.weight.data.uniform_(0, 0.05)\n",
    "        self.item_factors.weight.data.uniform_(0, 0.05)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        # data[] for movie indicies, takes user/movie pairs rep as index\n",
    "        users, items = data[:,0], data[:,1].long()\n",
    "        # dot product : user/movie position mult then sum into factor with axis=1\n",
    "        return (self.user_factors(users)*self.item_factors(items)).sum(1)\n",
    "    def predict(self, user, item):\n",
    "            return self.forward(user, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader creation, important part of pytorch?\n",
    "class Loader(Dataset):\n",
    "    def __init__(self):\n",
    "        self.ratings = ratings_df.copy()\n",
    "        \n",
    "        # Extract all user IDs and movie IDs\n",
    "        users = ratings_df.userId.unique()\n",
    "        movies = ratings_df.movieId.unique()\n",
    "        \n",
    "        # unique values dict, pair to index\n",
    "        self.userid2idx = {o:i for i,o in enumerate(users)}\n",
    "        self.movieid2idx = {o:i for i,o in enumerate(movies)}\n",
    "        \n",
    "        # append continuous ID for users and movies as .items in dict\n",
    "        self.idx2userid = {i:o for o,i in self.userid2idx.items()}\n",
    "        self.idx2movieid = {i:o for o,i in self.movieid2idx.items()}\n",
    "        \n",
    "        # baseball bat\n",
    "        self.ratings.movieId = ratings_df.movieId.apply(lambda x: self.movieid2idx[x])\n",
    "        self.ratings.userId = ratings_df.userId.apply(lambda x: self.userid2idx[x])\n",
    "        \n",
    "        # remove timestamp and rating, we got what we need\n",
    "        self.x = self.ratings.drop(['rating', 'timestamp'], axis=1).values\n",
    "        self.y = self.ratings['rating'].values\n",
    "        # convert x and y to tensor for model application\n",
    "        self.x, self.y = torch.tensor(self.x), torch.tensor(self.y)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MatrixFactorization(\n",
      "  (user_factors): Embedding(610, 8)\n",
      "  (item_factors): Embedding(9724, 8)\n",
      ")\n",
      "user_factors.weight tensor([[0.0270, 0.0275, 0.0194,  ..., 0.0058, 0.0134, 0.0433],\n",
      "        [0.0206, 0.0354, 0.0006,  ..., 0.0368, 0.0102, 0.0129],\n",
      "        [0.0487, 0.0023, 0.0120,  ..., 0.0005, 0.0307, 0.0201],\n",
      "        ...,\n",
      "        [0.0396, 0.0146, 0.0344,  ..., 0.0173, 0.0277, 0.0314],\n",
      "        [0.0362, 0.0068, 0.0135,  ..., 0.0139, 0.0390, 0.0479],\n",
      "        [0.0481, 0.0361, 0.0400,  ..., 0.0399, 0.0219, 0.0306]])\n",
      "item_factors.weight tensor([[2.5792e-02, 9.3603e-03, 4.2609e-03,  ..., 4.8535e-02, 2.5572e-02,\n",
      "         1.5382e-02],\n",
      "        [3.3251e-02, 1.0445e-02, 1.2220e-02,  ..., 2.3063e-02, 1.9611e-02,\n",
      "         2.9625e-02],\n",
      "        [1.2812e-02, 1.3770e-02, 7.5345e-03,  ..., 6.0316e-03, 4.2613e-02,\n",
      "         1.5097e-02],\n",
      "        ...,\n",
      "        [4.2221e-02, 1.2776e-02, 2.9391e-02,  ..., 2.9169e-03, 3.1951e-02,\n",
      "         1.1925e-02],\n",
      "        [3.6145e-02, 9.7863e-03, 1.6592e-02,  ..., 2.9972e-02, 3.4222e-03,\n",
      "         4.9919e-02],\n",
      "        [8.3140e-05, 4.8848e-02, 2.9453e-02,  ..., 1.3563e-02, 3.1485e-02,\n",
      "         4.1087e-02]])\n"
     ]
    }
   ],
   "source": [
    "# matrix model, set epoch to 100\n",
    "model = MatrixFactorization(n_users, n_items, n_factors=8)\n",
    "model = model.to(torch.float32)\n",
    "print(model)\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\n",
    "\n",
    "# Mean Squared Error loss function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# adam optimize\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# train data load and set\n",
    "train_set = Loader()\n",
    "train_loader = DataLoader(train_set, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.00033244032807818016\n",
      "Epoch [2/20], Loss: 0.00046850819181285365\n",
      "Epoch [3/20], Loss: 0.0005380677278970467\n",
      "Epoch [4/20], Loss: 0.0002825755193991987\n",
      "Epoch [5/20], Loss: 0.0004807516297452868\n",
      "Epoch [6/20], Loss: 0.00027337555133906535\n",
      "Epoch [7/20], Loss: 0.00037403010400482875\n",
      "Epoch [8/20], Loss: 0.00034668846692745937\n",
      "Epoch [9/20], Loss: 0.0003704183519890807\n",
      "Epoch [10/20], Loss: 0.00027101026890417277\n",
      "Epoch [11/20], Loss: 0.00037352349406073184\n",
      "Epoch [12/20], Loss: 0.00018202540777601501\n",
      "Epoch [13/20], Loss: 0.00023443711879113976\n",
      "Epoch [14/20], Loss: 0.0002986920187092867\n",
      "Epoch [15/20], Loss: 0.0003527723939496769\n",
      "Epoch [16/20], Loss: 0.00045731025715649304\n",
      "Epoch [17/20], Loss: 0.00036901398031161017\n",
      "Epoch [18/20], Loss: 0.00033267133299730225\n",
      "Epoch [19/20], Loss: 0.00019754175506569112\n",
      "Epoch [20/20], Loss: 0.0003787728674466121\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "                # Zero the gradients\n",
    "                optimizer.zero_grad()\n",
    "                # Forward pass\n",
    "                data = data.to(torch.int)\n",
    "                output = model(data)\n",
    "                # Compute loss\n",
    "                target = target.to(torch.float)\n",
    "                loss = loss_fn(output, target)\n",
    "                # Backpropagation\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        # Track total loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Print average loss per epoch\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {total_loss / len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_factors.weight tensor([[ 1.1092,  1.4594,  1.7066,  ...,  1.1963,  1.5360,  0.8710],\n",
      "        [ 0.1186,  0.3997,  0.9254,  ...,  1.1983,  1.0499,  2.4176],\n",
      "        [ 1.7261,  0.8074,  1.2782,  ..., -0.9178, -2.2086,  3.0694],\n",
      "        ...,\n",
      "        [ 0.4656,  0.5721,  2.1031,  ..., -0.4403,  0.5699,  0.8622],\n",
      "        [ 1.2982,  0.4542,  0.7090,  ...,  0.5769,  1.4522,  1.3640],\n",
      "        [ 2.0519,  0.8338,  0.9757,  ...,  1.1608,  0.6761,  0.8222]])\n",
      "item_factors.weight tensor([[0.4844, 0.4523, 0.1260,  ..., 0.6972, 0.6792, 0.5366],\n",
      "        [0.5464, 0.6324, 0.2943,  ..., 0.0963, 0.4942, 0.9471],\n",
      "        [0.7219, 0.2649, 0.2737,  ..., 0.2143, 0.4357, 0.6900],\n",
      "        ...,\n",
      "        [0.3822, 0.3513, 0.3700,  ..., 0.3422, 0.3734, 0.3508],\n",
      "        [0.4042, 0.3767, 0.3844,  ..., 0.3981, 0.3658, 0.4175],\n",
      "        [0.3966, 0.4464, 0.4257,  ..., 0.4104, 0.4269, 0.4391]])\n"
     ]
    }
   ],
   "source": [
    "# By training the model, we will have tuned latent factors for movies and users.\n",
    "c = 0\n",
    "uw = 0\n",
    "iw = 0 \n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\n",
    "        if c == 0:\n",
    "            uw = param.data\n",
    "            c +=1\n",
    "    else:\n",
    "        iw = param.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9724"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_movie_embeddings = model.item_factors.weight.data.cpu().numpy()\n",
    "len(trained_movie_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_Group #0\n",
      "\t Independence Day (a.k.a. ID4) (1996)\n",
      "\t Stargate (1994)\n",
      "\t Star Wars: Episode I - The Phantom Menace (1999)\n",
      "\t Dumb & Dumber (Dumb and Dumber) (1994)\n",
      "\t X-Men (2000)\n",
      "\t Twister (1996)\n",
      "\t Spider-Man (2002)\n",
      "\t Rock, The (1996)\n",
      "\t V for Vendetta (2006)\n",
      "\t Matrix Reloaded, The (2003)\n",
      "User_Group #1\n",
      "\t Godzilla (1998)\n",
      "\t I Still Know What You Did Last Summer (1998)\n",
      "\t Superman IV: The Quest for Peace (1987)\n",
      "\t Nutty Professor II: The Klumps (2000)\n",
      "\t Karate Kid, Part III, The (1989)\n",
      "\t House on Haunted Hill (1999)\n",
      "\t Kazaam (1996)\n",
      "\t Ghost Rider (2007)\n",
      "\t Flintstones in Viva Rock Vegas, The (2000)\n",
      "\t Stop! Or My Mom Will Shoot (1992)\n",
      "User_Group #2\n",
      "\t Terminator 2: Judgment Day (1991)\n",
      "\t Mask, The (1994)\n",
      "\t Terminator, The (1984)\n",
      "\t Babe (1995)\n",
      "\t Aliens (1986)\n",
      "\t Blade Runner (1982)\n",
      "\t Outbreak (1995)\n",
      "\t Ace Ventura: When Nature Calls (1995)\n",
      "\t Starship Troopers (1997)\n",
      "\t RoboCop (1987)\n",
      "User_Group #3\n",
      "\t Star Wars: Episode IV - A New Hope (1977)\n",
      "\t Toy Story (1995)\n",
      "\t Shrek (2001)\n",
      "\t Princess Bride, The (1987)\n",
      "\t Incredibles, The (2004)\n",
      "\t Ghostbusters (a.k.a. Ghost Busters) (1984)\n",
      "\t Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
      "\t Harry Potter and the Chamber of Secrets (2002)\n",
      "\t Harry Potter and the Prisoner of Azkaban (2004)\n",
      "\t Big (1988)\n",
      "User_Group #4\n",
      "\t Jurassic Park (1993)\n",
      "\t Apollo 13 (1995)\n",
      "\t Batman (1989)\n",
      "\t Aladdin (1992)\n",
      "\t True Lies (1994)\n",
      "\t Men in Black (a.k.a. MIB) (1997)\n",
      "\t Dances with Wolves (1990)\n",
      "\t Mission: Impossible (1996)\n",
      "\t Beauty and the Beast (1991)\n",
      "\t Die Hard: With a Vengeance (1995)\n",
      "User_Group #5\n",
      "\t Speed (1994)\n",
      "\t Mrs. Doubtfire (1993)\n",
      "\t Home Alone (1990)\n",
      "\t Net, The (1995)\n",
      "\t Clueless (1995)\n",
      "\t Cliffhanger (1993)\n",
      "\t Mummy, The (1999)\n",
      "\t Jerry Maguire (1996)\n",
      "\t Nutty Professor, The (1996)\n",
      "\t Santa Clause, The (1994)\n",
      "User_Group #6\n",
      "\t Groundhog Day (1993)\n",
      "\t Inception (2010)\n",
      "\t Léon: The Professional (a.k.a. The Professional) (Léon) (1994)\n",
      "\t Truman Show, The (1998)\n",
      "\t Amelie (Fabuleux destin d'Amélie Poulain, Le) (2001)\n",
      "\t Star Trek: Generations (1994)\n",
      "\t Natural Born Killers (1994)\n",
      "\t Shakespeare in Love (1998)\n",
      "\t Sin City (2005)\n",
      "\t Quiz Show (1994)\n",
      "User_Group #7\n",
      "\t Ace Ventura: Pet Detective (1994)\n",
      "\t Waterworld (1995)\n",
      "\t Trainspotting (1996)\n",
      "\t Happy Gilmore (1996)\n",
      "\t Broken Arrow (1996)\n",
      "\t Casino (1995)\n",
      "\t Mr. Holland's Opus (1995)\n",
      "\t Dogma (1999)\n",
      "\t Pirates of the Caribbean: Dead Man's Chest (2006)\n",
      "\t Django Unchained (2012)\n",
      "User_Group #8\n",
      "\t Schindler's List (1993)\n",
      "\t Godfather, The (1972)\n",
      "\t Fargo (1996)\n",
      "\t Twelve Monkeys (a.k.a. 12 Monkeys) (1995)\n",
      "\t Godfather: Part II, The (1974)\n",
      "\t Breakfast Club, The (1985)\n",
      "\t 2001: A Space Odyssey (1968)\n",
      "\t Donnie Darko (2001)\n",
      "\t Apocalypse Now (1979)\n",
      "\t Big Lebowski, The (1998)\n",
      "User_Group #9\n",
      "\t Forrest Gump (1994)\n",
      "\t Shawshank Redemption, The (1994)\n",
      "\t Silence of the Lambs, The (1991)\n",
      "\t Matrix, The (1999)\n",
      "\t Braveheart (1995)\n",
      "\t Star Wars: Episode V - The Empire Strikes Back (1980)\n",
      "\t Usual Suspects, The (1995)\n",
      "\t Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)\n",
      "\t Star Wars: Episode VI - Return of the Jedi (1983)\n",
      "\t Fugitive, The (1993)\n"
     ]
    }
   ],
   "source": [
    "# Fit the clusters based on the movie weights\n",
    "kmeans = KMeans(n_clusters=12, random_state=42).fit(trained_movie_embeddings)\n",
    "\n",
    "group_dict = {}\n",
    "\n",
    "for cluster in range(10):\n",
    "    print(\"User_Group #{}\".format(cluster))\n",
    "    movs = []\n",
    "    for movidx in np.where(kmeans.labels_ == cluster)[0]:\n",
    "        movid = train_set.idx2movieid[movidx]\n",
    "        rate_count = ratings_df.loc[ratings_df['movieId']==movid].count()[0]\n",
    "        movs.append((movie_titles[movid], rate_count))\n",
    "    for mov in sorted(movs, key=lambda tup: tup[1], reverse=True)[:10]:\n",
    "        print(\"\\t\", mov[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
